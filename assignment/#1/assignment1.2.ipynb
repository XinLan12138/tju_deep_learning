{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个部分与学长给的tutorial方法类似，探究了不同学习率下的成功率可能性，但是发现学习率的调整似乎对于最终准确率没有实质的影响，猜测原因可能是样本集较小的原因；\n",
    "此外，random_state选择正如他的名字而言，充满了随机性，在选择5、10的时候本样例可能可以达到当前分类的最高值，但是在其他随机种子的情况下，表现可能甚至无法超过50%，说明Logistic regression所训练出来的模型通用性可能不强，可能因为初始样本的随机化选择，而导致最终结果的较大差异！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sklearn.preprocessing as pre\n",
    "from matplotlib.pyplot import plot\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1.51596</td>\n",
       "      <td>12.79</td>\n",
       "      <td>3.61</td>\n",
       "      <td>1.62</td>\n",
       "      <td>72.97</td>\n",
       "      <td>0.64</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       RI     Na    Mg    Al     Si     K    Ca   Ba    Fe  class\n",
       "0   2  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.00      1\n",
       "1   3  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.00      1\n",
       "2   4  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.00      1\n",
       "3   5  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.00      1\n",
       "4   6  1.51596  12.79  3.61  1.62  72.97  0.64  8.07  0.0  0.26      1"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glass = pd.read_csv('../../dataset/glass_ident/glass.data')\n",
    "glass.columns = ['id', 'RI', 'Na', 'Mg', 'Al', 'Si', 'K','Ca','Ba','Fe','class']\n",
    "glass.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- there have class1,2,3,4,5,6,7, but class 4 is not in this work.\n",
    "- Two sub-tasks as follows:\n",
    "    1. Build a **logistic regression model to classify class 2 and not class 2**, i.e. a binary classifier to separate\n",
    "class 2 from everything else. This binary classifier should be able to **get an accuracy higher than 85%**\n",
    "\n",
    "    2. Build a **multiclass classification model** by build 6 binary classifiers. This multiclass classifier should be\n",
    "able to **get an accuracy higher than 50%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 二分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binClassifier(XTrain, yTrain, initRate, numEpoch=2000):\n",
    "    theta = np.zeros((XTrain.shape[1]))\n",
    "    lossList = []\n",
    "    learningRate = initRate\n",
    "    for epoch in range(numEpoch):\n",
    "        # forward \n",
    "        logits = np.dot(XTrain, theta)\n",
    "        hyp = 1/(1+np.exp(-logits))\n",
    "        \n",
    "        # uncomment this line to get an error.....\n",
    "        # hyp.shape = (hyp.size, 1) \n",
    "        \n",
    "        crossEntropyLoss = (-yTrain * np.log(hyp) - (1-yTrain)*np.log(1-hyp)).mean()\n",
    "\n",
    "        # backward\n",
    "        grad = (hyp - yTrain)@XTrain/yTrain.size\n",
    "        theta -= learningRate*grad\n",
    "\n",
    "        if epoch % 200 == 0:\n",
    "            print('Epoch', epoch, 'loss:', crossEntropyLoss)\n",
    "        if epoch % 200 == 0:\n",
    "            lossList.append(crossEntropyLoss)\n",
    "            \n",
    "            if len(lossList) > 5:\n",
    "                currentLoss = np.array(lossList[-5:-1])\n",
    "                if currentLoss.std()/currentLoss.mean() < 0.01:\n",
    "                    learningRate *= 0.95\n",
    "                    print('almost converged, lowering learning rate')\n",
    "            if learningRate/initRate < 0.5:\n",
    "                print('solution already converged, exit training')\n",
    "                break\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 多分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiClassifier(XTrain, yTrain, initRate=0.02):\n",
    "    numClass = np.unique(yTrain)\n",
    "    print(len(numClass), \" classes in total\")\n",
    "    params = np.zeros((len(numClass), XTrain.shape[1]))\n",
    "\n",
    "    for i in numClass:\n",
    "        print('\\nbegin to train a binary classifer for class ', i)\n",
    "        tempLabel = np.zeros_like(yTrain)\n",
    "        tempLabel[yTrain == numClass[i]] = 1\n",
    "        params[i,:] = binClassifier(XTrain, tempLabel, initRate)\n",
    "    \n",
    "    print('finish training for all classes!\\n')\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 可能预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predClass(params, XTest, yTest):\n",
    "    featSize = XTest.shape\n",
    "    labelSize = yTest.shape\n",
    "    assert(featSize[0]==labelSize[0])\n",
    "\n",
    "    logits = np.dot(XTest, np.transpose(params)).squeeze()\n",
    "    prob = 1 / (1+np.exp(-logits))\n",
    "\n",
    "    pred = np.argmax(prob, axis=1)\n",
    "    accuracy = np.sum(pred == yTest) / labelSize[0] * 100\n",
    "    pred[pred>=3]+=1\n",
    "    pred+=1\n",
    "    return prob, pred, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = glass.iloc[:,1:-1], pre.LabelEncoder().fit_transform(glass.iloc[:, -1])\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(X, y, test_size=0.3, random_state=5)\n",
    "featMean, featStd = np.mean(XTrain, axis=0), np.std(XTrain, axis=0)\n",
    "XTrain = (XTrain - featMean) / featStd\n",
    "XTest = (XTest - featMean) / featStd\n",
    "\n",
    "# Concatenate X with a new dimension for bias\n",
    "XTrain = np.concatenate((np.ones((XTrain.shape[0], 1)), XTrain), axis=1)\n",
    "XTest = np.concatenate((np.ones((XTest.shape[0], 1)), XTest), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6  classes in total\n",
      "\n",
      "begin to train a binary classifer for class  0\n",
      "Epoch 0 loss: 0.69314718056\n",
      "Epoch 200 loss: 0.635602231929\n",
      "Epoch 400 loss: 0.597798834125\n",
      "Epoch 600 loss: 0.571320764596\n",
      "Epoch 800 loss: 0.551722156761\n",
      "Epoch 1000 loss: 0.536585493545\n",
      "Epoch 1200 loss: 0.524509817886\n",
      "Epoch 1400 loss: 0.514629913154\n",
      "Epoch 1600 loss: 0.506381445358\n",
      "Epoch 1800 loss: 0.499379529834\n",
      "\n",
      "begin to train a binary classifer for class  1\n",
      "Epoch 0 loss: 0.69314718056\n",
      "Epoch 200 loss: 0.669227108302\n",
      "Epoch 400 loss: 0.653686787321\n",
      "Epoch 600 loss: 0.643101211727\n",
      "Epoch 800 loss: 0.635574575195\n",
      "Epoch 1000 loss: 0.630028648521\n",
      "Epoch 1200 loss: 0.625820747119\n",
      "Epoch 1400 loss: 0.622549024969\n",
      "Epoch 1600 loss: 0.619951378719\n",
      "almost converged, lowering learning rate\n",
      "Epoch 1800 loss: 0.617945543032\n",
      "almost converged, lowering learning rate\n",
      "\n",
      "begin to train a binary classifer for class  2\n",
      "Epoch 0 loss: 0.69314718056\n",
      "Epoch 200 loss: 0.598673663198\n",
      "Epoch 400 loss: 0.528618247519\n",
      "Epoch 600 loss: 0.476006062895\n",
      "Epoch 800 loss: 0.435884383166\n",
      "Epoch 1000 loss: 0.404798732847\n",
      "Epoch 1200 loss: 0.380339521252\n",
      "Epoch 1400 loss: 0.360811711467\n",
      "Epoch 1600 loss: 0.345008191312\n",
      "Epoch 1800 loss: 0.332057370824\n",
      "\n",
      "begin to train a binary classifer for class  3\n",
      "Epoch 0 loss: 0.69314718056\n",
      "Epoch 200 loss: 0.583182502221\n",
      "Epoch 400 loss: 0.502244565884\n",
      "Epoch 600 loss: 0.441632279307\n",
      "Epoch 800 loss: 0.395331939796\n",
      "Epoch 1000 loss: 0.359259809965\n",
      "Epoch 1200 loss: 0.330632013865\n",
      "Epoch 1400 loss: 0.307525134454\n",
      "Epoch 1600 loss: 0.288587317293\n",
      "Epoch 1800 loss: 0.272851170742\n",
      "\n",
      "begin to train a binary classifer for class  4\n",
      "Epoch 0 loss: 0.69314718056\n",
      "Epoch 200 loss: 0.584839874416\n",
      "Epoch 400 loss: 0.504403505558\n",
      "Epoch 600 loss: 0.443821499558\n",
      "Epoch 800 loss: 0.397396862131\n",
      "Epoch 1000 loss: 0.361174983464\n",
      "Epoch 1200 loss: 0.332416140286\n",
      "Epoch 1400 loss: 0.309206020753\n",
      "Epoch 1600 loss: 0.290189125716\n",
      "Epoch 1800 loss: 0.27439097477\n",
      "\n",
      "begin to train a binary classifer for class  5\n",
      "Epoch 0 loss: 0.69314718056\n",
      "Epoch 200 loss: 0.559406014909\n",
      "Epoch 400 loss: 0.470044587953\n",
      "Epoch 600 loss: 0.407258092442\n",
      "Epoch 800 loss: 0.361149608587\n",
      "Epoch 1000 loss: 0.326037106605\n",
      "Epoch 1200 loss: 0.298495161981\n",
      "Epoch 1400 loss: 0.27635995839\n",
      "Epoch 1600 loss: 0.258207268932\n",
      "Epoch 1800 loss: 0.243065781268\n",
      "finish training for all classes!\n",
      "\n",
      "Prediction: [2 2 2 1 2 7 7 1 1 1 2 2 2 2 1 1 2 7 2 2 2 2 2 1 1 1 2 7 2 1 5 1 2 7 1 7 7\n",
      " 2 2 2 1 1 2 1 2 2 1 2 1 2 7 7 1 7 2 2 7 2 1 2 1 2 1 1]\n",
      "\n",
      "Accuracy: 62.500%\n"
     ]
    }
   ],
   "source": [
    "initRate = 0.003\n",
    "params = multiClassifier(XTrain, yTrain, initRate)\n",
    "_, preds, accu = predClass(params, XTest, yTest)\n",
    "print(\"Prediction: {}\\n\".format(preds))\n",
    "print(\"Accuracy: {:.3f}%\".format(accu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 使用循环大规模实验进行合理的学习率测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binClassifier(XTrain, yTrain, initRate, numEpoch=2000):\n",
    "    theta = np.zeros((XTrain.shape[1]))\n",
    "    lossList = []\n",
    "    learningRate = initRate\n",
    "    for epoch in range(numEpoch):\n",
    "        # forward \n",
    "        logits = np.dot(XTrain, theta)\n",
    "        hyp = 1/(1+np.exp(-logits))\n",
    "        \n",
    "        # uncomment this line to get an error.....\n",
    "        # hyp.shape = (hyp.size, 1) \n",
    "        \n",
    "        crossEntropyLoss = (-yTrain * np.log(hyp) - (1-yTrain)*np.log(1-hyp)).mean()\n",
    "\n",
    "        # backward\n",
    "        grad = (hyp - yTrain)@XTrain/yTrain.size\n",
    "        theta -= learningRate*grad\n",
    "\n",
    "        if epoch % 1000 == 0:\n",
    "            #print('Epoch', epoch, 'loss:', crossEntropyLoss)\n",
    "         if epoch % 50 == 0:\n",
    "            lossList.append(crossEntropyLoss)\n",
    "            if len(lossList) > 5:\n",
    "                currentLoss = np.array(lossList[-5:-1])\n",
    "                if currentLoss.std()/currentLoss.mean() < 0.01:\n",
    "                    learningRate *= 0.95\n",
    "                    #print('almost converged, lowering learning rate')\n",
    "            if learningRate/initRate < 0.5:\n",
    "                #print('solution already converged, exit training')\n",
    "                break\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = glass.iloc[:,1:-1], pre.LabelEncoder().fit_transform(glass.iloc[:, -1])\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(X, y, test_size=0.3, random_state=5)\n",
    "featMean, featStd = np.mean(XTrain, axis=0), np.std(XTrain, axis=0)\n",
    "XTrain = (XTrain - featMean) / featStd\n",
    "XTest = (XTest - featMean) / featStd\n",
    "\n",
    "# Concatenate X with a new dimension for bias\n",
    "XTrain = np.concatenate((np.ones((XTrain.shape[0], 1)), XTrain), axis=1)\n",
    "XTest = np.concatenate((np.ones((XTest.shape[0], 1)), XTest), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current learing rate:  0.0001\n",
      "6  classes in total\n",
      "\n",
      "begin to train a binary classifer for class  0\n",
      "\n",
      "begin to train a binary classifer for class  1\n",
      "\n",
      "begin to train a binary classifer for class  2\n",
      "\n",
      "begin to train a binary classifer for class  3\n",
      "\n",
      "begin to train a binary classifer for class  4\n",
      "\n",
      "begin to train a binary classifer for class  5\n",
      "finish training for all classes!\n",
      "\n",
      "Accuracy: 62.500%\n",
      "current learing rate:  0.0002\n",
      "6  classes in total\n",
      "\n",
      "begin to train a binary classifer for class  0\n",
      "\n",
      "begin to train a binary classifer for class  1\n",
      "\n",
      "begin to train a binary classifer for class  2\n",
      "\n",
      "begin to train a binary classifer for class  3\n",
      "\n",
      "begin to train a binary classifer for class  4\n",
      "\n",
      "begin to train a binary classifer for class  5\n",
      "finish training for all classes!\n",
      "\n",
      "Accuracy: 62.500%\n",
      "current learing rate:  0.0005\n",
      "6  classes in total\n",
      "\n",
      "begin to train a binary classifer for class  0\n",
      "\n",
      "begin to train a binary classifer for class  1\n",
      "\n",
      "begin to train a binary classifer for class  2\n",
      "\n",
      "begin to train a binary classifer for class  3\n",
      "\n",
      "begin to train a binary classifer for class  4\n",
      "\n",
      "begin to train a binary classifer for class  5\n",
      "finish training for all classes!\n",
      "\n",
      "Accuracy: 62.500%\n",
      "current learing rate:  0.001\n",
      "6  classes in total\n",
      "\n",
      "begin to train a binary classifer for class  0\n",
      "\n",
      "begin to train a binary classifer for class  1\n",
      "\n",
      "begin to train a binary classifer for class  2\n",
      "\n",
      "begin to train a binary classifer for class  3\n",
      "\n",
      "begin to train a binary classifer for class  4\n",
      "\n",
      "begin to train a binary classifer for class  5\n",
      "finish training for all classes!\n",
      "\n",
      "Accuracy: 62.500%\n",
      "current learing rate:  0.002\n",
      "6  classes in total\n",
      "\n",
      "begin to train a binary classifer for class  0\n",
      "\n",
      "begin to train a binary classifer for class  1\n",
      "\n",
      "begin to train a binary classifer for class  2\n",
      "\n",
      "begin to train a binary classifer for class  3\n",
      "\n",
      "begin to train a binary classifer for class  4\n",
      "\n",
      "begin to train a binary classifer for class  5\n",
      "finish training for all classes!\n",
      "\n",
      "Accuracy: 62.500%\n",
      "current learing rate:  0.003\n",
      "6  classes in total\n",
      "\n",
      "begin to train a binary classifer for class  0\n",
      "\n",
      "begin to train a binary classifer for class  1\n",
      "\n",
      "begin to train a binary classifer for class  2\n",
      "\n",
      "begin to train a binary classifer for class  3\n",
      "\n",
      "begin to train a binary classifer for class  4\n",
      "\n",
      "begin to train a binary classifer for class  5\n",
      "finish training for all classes!\n",
      "\n",
      "Accuracy: 62.500%\n",
      "current learing rate:  0.004\n",
      "6  classes in total\n",
      "\n",
      "begin to train a binary classifer for class  0\n",
      "\n",
      "begin to train a binary classifer for class  1\n",
      "\n",
      "begin to train a binary classifer for class  2\n",
      "\n",
      "begin to train a binary classifer for class  3\n",
      "\n",
      "begin to train a binary classifer for class  4\n",
      "\n",
      "begin to train a binary classifer for class  5\n",
      "finish training for all classes!\n",
      "\n",
      "Accuracy: 62.500%\n",
      "current learing rate:  0.005\n",
      "6  classes in total\n",
      "\n",
      "begin to train a binary classifer for class  0\n",
      "\n",
      "begin to train a binary classifer for class  1\n",
      "\n",
      "begin to train a binary classifer for class  2\n",
      "\n",
      "begin to train a binary classifer for class  3\n",
      "\n",
      "begin to train a binary classifer for class  4\n",
      "\n",
      "begin to train a binary classifer for class  5\n",
      "finish training for all classes!\n",
      "\n",
      "Accuracy: 62.500%\n",
      "current learing rate:  0.01\n",
      "6  classes in total\n",
      "\n",
      "begin to train a binary classifer for class  0\n",
      "\n",
      "begin to train a binary classifer for class  1\n",
      "\n",
      "begin to train a binary classifer for class  2\n",
      "\n",
      "begin to train a binary classifer for class  3\n",
      "\n",
      "begin to train a binary classifer for class  4\n",
      "\n",
      "begin to train a binary classifer for class  5\n",
      "finish training for all classes!\n",
      "\n",
      "Accuracy: 62.500%\n",
      "current learing rate:  0.015\n",
      "6  classes in total\n",
      "\n",
      "begin to train a binary classifer for class  0\n",
      "\n",
      "begin to train a binary classifer for class  1\n",
      "\n",
      "begin to train a binary classifer for class  2\n",
      "\n",
      "begin to train a binary classifer for class  3\n",
      "\n",
      "begin to train a binary classifer for class  4\n",
      "\n",
      "begin to train a binary classifer for class  5\n",
      "finish training for all classes!\n",
      "\n",
      "Accuracy: 62.500%\n",
      "current learing rate:  0.02\n",
      "6  classes in total\n",
      "\n",
      "begin to train a binary classifer for class  0\n",
      "\n",
      "begin to train a binary classifer for class  1\n",
      "\n",
      "begin to train a binary classifer for class  2\n",
      "\n",
      "begin to train a binary classifer for class  3\n",
      "\n",
      "begin to train a binary classifer for class  4\n",
      "\n",
      "begin to train a binary classifer for class  5\n",
      "finish training for all classes!\n",
      "\n",
      "Accuracy: 62.500%\n",
      "current learing rate:  0.025\n",
      "6  classes in total\n",
      "\n",
      "begin to train a binary classifer for class  0\n",
      "\n",
      "begin to train a binary classifer for class  1\n",
      "\n",
      "begin to train a binary classifer for class  2\n",
      "\n",
      "begin to train a binary classifer for class  3\n",
      "\n",
      "begin to train a binary classifer for class  4\n",
      "\n",
      "begin to train a binary classifer for class  5\n",
      "finish training for all classes!\n",
      "\n",
      "Accuracy: 62.500%\n",
      "current learing rate:  0.03\n",
      "6  classes in total\n",
      "\n",
      "begin to train a binary classifer for class  0\n",
      "\n",
      "begin to train a binary classifer for class  1\n",
      "\n",
      "begin to train a binary classifer for class  2\n",
      "\n",
      "begin to train a binary classifer for class  3\n",
      "\n",
      "begin to train a binary classifer for class  4\n",
      "\n",
      "begin to train a binary classifer for class  5\n",
      "finish training for all classes!\n",
      "\n",
      "Accuracy: 62.500%\n",
      "current learing rate:  0.035\n",
      "6  classes in total\n",
      "\n",
      "begin to train a binary classifer for class  0\n",
      "\n",
      "begin to train a binary classifer for class  1\n",
      "\n",
      "begin to train a binary classifer for class  2\n",
      "\n",
      "begin to train a binary classifer for class  3\n",
      "\n",
      "begin to train a binary classifer for class  4\n",
      "\n",
      "begin to train a binary classifer for class  5\n",
      "finish training for all classes!\n",
      "\n",
      "Accuracy: 62.500%\n",
      "current learing rate:  0.04\n",
      "6  classes in total\n",
      "\n",
      "begin to train a binary classifer for class  0\n",
      "\n",
      "begin to train a binary classifer for class  1\n",
      "\n",
      "begin to train a binary classifer for class  2\n",
      "\n",
      "begin to train a binary classifer for class  3\n",
      "\n",
      "begin to train a binary classifer for class  4\n",
      "\n",
      "begin to train a binary classifer for class  5\n",
      "finish training for all classes!\n",
      "\n",
      "Accuracy: 62.500%\n",
      "current learing rate:  0.045\n",
      "6  classes in total\n",
      "\n",
      "begin to train a binary classifer for class  0\n",
      "\n",
      "begin to train a binary classifer for class  1\n",
      "\n",
      "begin to train a binary classifer for class  2\n",
      "\n",
      "begin to train a binary classifer for class  3\n",
      "\n",
      "begin to train a binary classifer for class  4\n",
      "\n",
      "begin to train a binary classifer for class  5\n",
      "finish training for all classes!\n",
      "\n",
      "Accuracy: 62.500%\n",
      "current learing rate:  0.05\n",
      "6  classes in total\n",
      "\n",
      "begin to train a binary classifer for class  0\n",
      "\n",
      "begin to train a binary classifer for class  1\n",
      "\n",
      "begin to train a binary classifer for class  2\n",
      "\n",
      "begin to train a binary classifer for class  3\n",
      "\n",
      "begin to train a binary classifer for class  4\n",
      "\n",
      "begin to train a binary classifer for class  5\n",
      "finish training for all classes!\n",
      "\n",
      "Accuracy: 62.500%\n"
     ]
    }
   ],
   "source": [
    "lr_set = np.array([0.0001,0.0002,0.0005,0.001,0.002,0.003,0.004,0.005,\\\n",
    "             0.01,0.015,0.02,0.025,0.03,0.035,0.04,0.045,0.05])\n",
    "accuList  = []\n",
    "for lr in lr_set:\n",
    "    print('current learing rate: ', lr)\n",
    "    params = multiClassifier(XTrain, yTrain, initRate)\n",
    "    _, preds, accu = predClass(params, XTest, yTest)\n",
    "    predsList.append(preds)\n",
    "    accuList.append(accu)\n",
    "    #print(\"Prediction: {}\\n\".format(preds))\n",
    "    print(\"Accuracy: {:.3f}%\".format(accu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[62.5,\n",
       " 62.5,\n",
       " 62.5,\n",
       " 62.5,\n",
       " 62.5,\n",
       " 62.5,\n",
       " 62.5,\n",
       " 62.5,\n",
       " 62.5,\n",
       " 62.5,\n",
       " 62.5,\n",
       " 62.5,\n",
       " 62.5,\n",
       " 62.5,\n",
       " 62.5,\n",
       " 62.5,\n",
       " 62.5]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由此发现在一定范围内，调整学习率后，最终预测的准确率都是基本上一样敏感"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多类之下，总体的分类成功率可能因为个别类别较少的分类判断错误，而拉低成功率！"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
